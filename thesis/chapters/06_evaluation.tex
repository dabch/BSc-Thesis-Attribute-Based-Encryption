\chapter{Evaluation}\label{chap:evaluation}
This chapter shall present the results of my study and discuss the implications of what was observed.

The performance of \acrlong{abe} depends on the underlying implementation of the elliptic curves and pairing.
Therefore, the performance of the ported \texttt{rabe-bn} library will be evaluated in section~\ref{sec:rabebn-evaluation} before analyzing the performance of the \acrshortpl{abes} in section~\ref{sec:abe-performance}.

\section{Performance of \texttt{rabe\_bn}}\label{sec:rabebn-evaluation}

Table~\ref{tbl:rabebn-performance} displays performance measurements of random element sampling, group-scalar exponentiation and the pairing operation with the \verb+rabe_bn+ library.
The times have been measured using randomly sampled elements and averaged over 100 calls of each operation.

\begin{center}
    \begin{tabular}{|c|r|r|}\hline%
        Operation & SoC [ms] & Laptop [ms]\\\hline\hline
        \csvreader[late after line=\\]%
        {data/bn-smpl.csv}{op=\op,soc=\soc,laptop=\laptop}%
        {\op&\soc&\laptop}%
        % \hline
        % \csvreader[late after line=\\]%
        % {data/bn-groupop.csv}{op=\op,soc=\soc,laptop=\laptop}%
        % {\op&\soc&\laptop}%
        \hline
        \csvreader[late after line=\\]%
        {data/bn-groupexp.csv}{op=\op,soc=\soc,laptop=\laptop}%
        {\op&\soc&\laptop}%
        \hline
        \csvreader[late after line=\\]%
        {data/bn-pairing.csv}{op=\op,soc=\soc,laptop=\laptop}%
        {\op&\soc&\laptop}%
        \hline
    \end{tabular}  
    \captionof{table}{Execution times for various operations on the SoC and the laptop}
    \label{tbl:rabebn-performance}
\end{center}


It is evident that the the cost of the operations differs greatly between the groups. 
Sampling a random element takes about the same time as group exponentiation for $\mathbb{G}_1$ and $\mathbb{G}_2$, but is significantly more costly for $\mathbb{G}_T$.
Looking at the implementation, the reason for this is obvious: Sampling from $\mathbb{G}_1$ and $\mathbb{G}_2$ simply generates a random $z \in \mathbb{F}_r$ and returns the group element $z \cdot G$ for $G$ a generator.
Sampling from $\mathbb{G}_T$ is done by generating random elements of $\mathbb{G}_1$ and $\mathbb{G}_2$ and computing their pairing.
This is reflected in the measured timings.

RAM size is a major limiting factor for pairing computation.
During development, I also tested the ported \texttt{rabe-bn} library on the nRF52832 SoC, which has 64\,KB of RAM (vs. 256\,KB in the nRF52840). 
On this chip, a pairing could be computed successfully only if the library was built \emph{without debug symbols}.
With debug symbols, there was not enough RAM available and the pairing computation failed.
This suggests that the memory use during pairing computation is close to 64\,KB, which would still be a quarter of the RAM on the nRF52840 SoC.
While this memory is not consumed permanently, it still needs to be available when the pairing function is called.

Measurement of the RAM use with Valgrind on the laptop shows that one pairing computation needs 58,552\,KB of RAM.
This is indeed close to the 64\,KB available on the nRF52832 SoC.

\section{Evaluation of the ABE library}\label{sec:abe-performance}

In this section, the performance of the four algorithms Encrypt, Decrypt, Setup and KeyGen of the two \acrshort{abe} schemes GPSW and YCT will be evaluated.

The results of the runtime analysis are presented in Figures~\ref{fig:abe-performance-diagrams-gpsw} and \ref{fig:abe-performance-diagrams-yct}. 
RAM use is shown in Figure~\ref{fig:abe-performance-diagrams-ram}; flash use is depicted in Figure~\ref{fig:abe-performance-diagrams-flash}. 


\subsection{Methods of measurement}
This section describes how the presented result were obtained.

\subsubsection{Time measurements}
\input{figures/06_diagrams_timing}

All time measurements were performed using a hardware timer on the nRF52840 SoC.

The runtime of \acrshort{abe} operations is not constant, but depends on the number of attributes and / or the complexity of the used policy.

For Setup, the number of attributes refers to the total number of attributes in the system.
For Encrypt, the number of attributes refers to the number of attributes under which the ciphertext is encrypted.

For KeyGen, the number of attributes refers to the number of leaf nodes in the used access policy.
The \glspl{access-tree} are flat, i.e. they consists only of a root node and the given number of children.
To ensure that all leaves have to be evaluated, the root's threshold is set to the number of children (i.e. it acts as an \emph{AND} node).
This approach is also found in other evaluations of \acrshort{abe}~\cite{girgenti_feasibility_2019}.

For Decrypt, the same access policies from KeyGen are used to decrypt a ciphertext encrypted with all system attributes.
This ensures that the ciphertext can always be decrypted, and does not influence the decryption speed.

For reference, the same measurements were made on the laptop.
These timings are included in Appendix~\ref{sec:appendix_laptop}.

\subsubsection{RAM use measurements}
\input{figures/06_diagrams_ram}

RAM use was only measured for encryption and decryption. 
For encryption it is constant and is included in Figure~\ref{fig:abe-performance-diagrams-ram} only for reference.
The RAM use of decryption depends mostly on the depth of the \gls{access-tree}.
For this reason, the flat policies from the timing evaluation could not be re-used for RAM evaluation.
Instead, \glspl{access-tree} in the shape of \glspl{perfect-binary-tree} were employed.
That means that all nodes have exactly two children and all leaves are on the lowest level of the tree.
This yields the maximum number of nodes for a given depth.

The values were obtained by running decryption on the laptop and measuring the RAM use using Valgrind's \texttt{Massif} tool~\cite{nethercote_massif_nodate}.
Valgrind is a tool suite for analyzing memory use and memory management of programs.
Massif itself is originally a heap profiler, but can also be used to measure the stack's memory use with the option \verb+--stacks=yes+.
Heap use is not profiled because our library is specifically written to work without the heap.

Massif outputs a number of measurements over the runtime of the program. 
The presented values represent the maximum stack memory use during the entire runtime.

It is assumed that RAM use on the laptop is representative for RAM use on the SoC.
This is in line with other evaluations of \acrshort{abe}~\cite{borgh_attribute-based_2016}. 
Decryption with the same policies on the SoC confirmed the assumption:
With three- and four-level policies, decryption failed on the SoC, but it worked with one- and two-level policies.
The RAM use on the laptop is below 256\,KB (the RAM size of the SoC) for the two-level policy, but above 256\,KB for the three-level policy.

\subsubsection{Flash size measurements}
\input{figures/06_diagrams_flash}

The sizes of the executable binaries were measured by calling \verb+cargo size -- -A+ with optimizations on a binary crate that contains a minimal code snippet calling the respective \acrshort{abe} library.
\verb+cargo size+ is part of \verb+cargo-binutils+~\cite{noauthor_cargo-binutils_nodate}, which provides access to the LLVM tools in the Rust toolchain.
The values presented in Figure~\ref{fig:abe-performance-diagrams-flash} are the combined size of the \texttt{text}, \texttt{rodata} and \texttt{bss} segments.


\subsection{Results}
The pairing-free YCT scheme is significantly faster than the pairing-based GPSW scheme in all four algorithms. 
For both schemes, Setup takes about the same time as Encryption for the same number of attributes in the system or ciphertext, respectively.
The runtime of Setup and Encrypt with GPSW is about 3.5\,s longer than with YCT, independent on the number of attributes.
% On the SoC, setup and encryption with a single attribute take about 4 seconds with GPSW and only about 0.4 seconds with YCT.
% With 30 attributes, GPSW requires about 8.5 seconds and YCT about 5 seconds.
The runtimes increase linearly in both, with each additional attribute adding about 150\,ms.

For the KeyGen algorithm, difference is even larger:
The runtime of GPSW increases considerably with larger policies.
With a single-attribute policy, KeyGen takes about 650\,ms. With 25 attributes, it already takes more than 16 seconds.
The runtime of YCT only increases slightly from 35\,ms for one attribute to 210\,ms for 25 attributes.

Decryption time is also linear with both schemes.
Again, YCT is much faster at 12\,s for the largest policy with 30\,attributes. GPSW requires 80\,s for the largest policy.

The RAM usage also shows a large advantage for YCT:
With GPSW, a single-level policy already uses up more than three times more RAM than YCT; this difference only increases with more policy levels.
Assuming RAM use on the laptop is representative for the SoC, the single-level policy already requires more than two thirds of the total RAM on the sensor.
With three or more levels, decryption fails entirely on the SoC because there is not enough RAM.
YCT does not have this problem: Even with a four-level policy, it uses only the equivalent of about a quarter of the total RAM.

The difference in flash size is not as big, but the GPSW scheme still requires about 70\,\% more flash storage than the YCT scheme.


\section{Discussion}
The timings of Setup and Encrypt are in line with the time-consuming operations performed by the algorithms: 
In both schemes, each additional attribute results in one additional exponentiation in $\mathbb{G}_1$.
This takes about 150\,ms as per Table~\ref{tbl:rabebn-performance}, which is exactly the additional time per attribute.
The constant overhead of about 3.5\,s with GPSW is a result of the pairing computation and exponentiation in $\mathbb{G}_T$ (for Setup) and the sampling and exponentiation in $\mathbb{G}_T$ (for Encrypt).

This contradicts the result from \cite{girgenti_feasibility_2019}, where the encryption performance of GPSW and YCT are explicitly noted to be equivalent.
However, their conclusion is based on very small numbers of attributes for YCT due to a bug in the evaluated library~\cite{girgenti_feasibility_2019}.
In addition, their SoC is significantly faster than ours (240\,MHz vs. 64\,MHz), thus the constant overhead of GPSW is smaller.

For the KeyGen algorithm, the speed difference between YCT and GSPW is especially striking: 
The runtime of the YCT KeyGen algorithm is in the order of a few hundred milliseconds whereas GPSW takes almost 20\,s with the largest policies.
Again, looking at the schemes, the reason becomes evident: YCT's KeyGen only works on elements of $\mathbb{F}_r$, which are small and easy to calculate with.
GPSW uses secret shares from $\mathbb{G}_2$, for which operations take considerably more time.
This is also the case for decryption: YCT only requires exponentation and point addition in $\mathbb{G}_1$, whereas GPSW performs pairings, multiplications and exponentiations in $\mathbb{G}_T$.

The RAM consumption of decryption with GPSW is a limiting factor on the SoC:
Decryption with policies of more than two levels fails because of too little memory.
This poses a hard limit on the size of \glspl{access-policy}.
Also, in our evaluation, the \acrshort{abe} library was able to use  the entire RAM on the SoC.
In a real-world use case, the application employing \acrshort{abe} might already occupy a considerable portion of the available RAM, leaving too little space even for decryption with small \glspl{access-tree}.
The pairing-free YCT scheme uses much less RAM and is thus less affected by these issues.\\

If some latency is acceptable and the number of attributes is not too large, doing encryption with \acrshort{abe} on the SoC is feasible.
The pairing-free YCT scheme is faster and requires less memory, but the pairing-free GPSW scheme still performs well enough.

If decryption on the SoC is necessary, the YCT scheme is to be preferred:
With GPSW, decryption takes considerably more time and uses a large amount of RAM.
This results in the mentioned hard limit on the policy depth, which is not present with YCT.

However, as the security of pairing-free \acrshort{abes} is questioned (see \cite{herranz_attacking_2020}), a pairing-based scheme might be preferable.
Therefore, in applications where only encryption is necessary on the SoC, the GPSW scheme might be preferred over YCT.

The other two algorithms, Setup and KeyGen, are run only by the \acrshort{kgc}.
Therefore, it is reasonable to assume that these don't need to be run on a constrained node in real-world scenarios.
The \acrshort{kgc} would probably be a specially protected PC or at least a more powerful \acrshort{iot} node (e.g. Raspberry Pi).

\section{Further Improvements / Future Work}

The implementations evaluated in this thesis offer room for improvement.
For example if only encryption is needed on the SoC, the library could be split into two:
A limited, bare-metal library that implements only encryption and runs on the SoC, and a full library that runs on the \acrshort{kgc} and other devices.
This would enable \acrshort{abe} encryption on the sensor while allowing the full library to rely on a full-fledged operating system.

Regarding the results on the SoC, improvements could be made by improving the underlying pairing and elliptic curve implementation of the \texttt{rabe-bn} library.
Even though the operations remain computationally expensive, other implementations do better:
In \cite{scott_deployment_2020}, the \emph{MIRACL Core} library was tested on the same SoC as ours using the same type of curve (256-bit BN curve).
This library evaluates a pairing in about 600\,ms; our library takes 1600\,ms. 
Exponentiation in $\mathbb{G}_T$ takes about 300\,ms with their library and about 1400\,ms with ours. 
Both libraries are high-level implementations (i.e. no optimized assembly code), and thus it is likely that the optimizations from \emph{MIRACL Core} could be carried over to Rust.
As the runtime of \acrshort{abe} is dominated by these expensive curve operations, an improved pairing and curve implementation offers considerable potential for speedup.
These improvements, however, are clearly outside the scope of this thesis.

Runtimes in the order of several seconds might still be too long, even if improved by a better pairing library.
Usually, a new symmetric key is generated and encrypted under \acrshort{abe} for every message, but this is not strictly necessary:
By saving both the symmetric key and its \acrshort{abe}-encrypted version, more than one message can be encrypted with the same symmetric key.
A single \acrshort{abe} encryption operation can then be used for many messages.
The encyptor may periodically generate and encrypt a new symmetric key (e.g. once per day).
If the messages should be decryptable on their own, the \acrshort{abe}-encrypted symmetric key can be copied into each encrypted message.
The downside is that all messages encrypted with the same symmetric key naturally have the same attributes or access policy attached (i.e. reduced granularity).
Also, if the symmetric key is compromised (possibly while it is stored to encrypt the next message), all messages encrypted with that key will be compromised.

This approach does not reduce the ciphertext size if the \acrshort{abe}-encrypted key is copied into each ciphertext.
If this is an issue (e.g. due to low-power wireless transmission), the \acrshort{abe}-encrypted key may be transmitted separately from the symmetrically encrypted messages.
Then both the symmetric ciphertext and the respective \acrshort{abe}-encrypted key must be present to decrypt a message.

This symmetric key-caching approach was implemented for use in a system similar to that presented in Figure~\ref{fig:system-architecture}.
However, it was not evaluated for this thesis, because it doesn't allow the same flexibility as \acrlong{abe}.
~\\

The two schemes implemented in the library are \acrshort{kp-abe} schemes, currently no \acrshort{cp-abe} schemes are implemented.
\acrshort{cp-abe} on constrained devices is covered in~\cite{borgh_attribute-based_2016}, but further evaluation is left as future work.
The implemented schemes also don't support key revocation or a \gls{large-universe} of attributes. 
Implementation and evaluation of those is also left for future projects.
